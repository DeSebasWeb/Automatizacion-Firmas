Necesito MAXIMIZAR la precisi√≥n de Google Cloud Vision API para extracci√≥n de c√©dulas manuscritas antes de considerar soluciones m√°s costosas. El proyecto ya tiene implementaci√≥n b√°sica de Vision API, ahora vamos a aplicar TODAS las optimizaciones avanzadas disponibles.

CONTEXTO:
- Aplicaci√≥n de digitaci√≥n con Google Cloud Vision API ya funcionando
- Precisi√≥n actual con opciones gratuitas (Tesseract, PaddleOCR, EasyOCR): <50%
- Necesitamos alcanzar 90%+ de precisi√≥n con Vision API
- Si no lo logramos, se considerar√° Document AI Custom (~$930k COP inversi√≥n)
- Arquitectura hexagonal ya implementada
- Autenticaci√≥n: gcloud auth application-default

OBJETIVO:
Implementar TODAS las optimizaciones avanzadas de Google Cloud Vision API para maximizar precisi√≥n sin costo adicional.

OPTIMIZACIONES A IMPLEMENTAR:

1. CAMBIAR A DOCUMENT_TEXT_DETECTION
Actualmente usamos TEXT_DETECTION (gen√©rico).
Migrar a DOCUMENT_TEXT_DETECTION (especializado en documentos estructurados).

Diferencia cr√≠tica:
- TEXT_DETECTION: Para carteles, se√±ales, texto general
- DOCUMENT_TEXT_DETECTION: Entiende estructura de documentos, p√°rrafos, tablas, columnas

Implementar:
- Usar document_text_detection() en lugar de text_detection()
- Procesar respuesta estructurada (pages -> blocks -> paragraphs -> words)

2. USAR BOUNDING BOXES Y CONFIDENCE SCORES
Vision retorna coordenadas exactas y confianza por cada palabra detectada.

Implementar:
- Extraer bounding_box de cada word
- Filtrar por confidence > 0.85
- Usar coordenadas para segmentaci√≥n inteligente

Estructura de datos:
```python
for page in response.full_text_annotation.pages:
    for block in page.blocks:
        for paragraph in block.paragraphs:
            for word in paragraph.words:
                word_text = ''.join([symbol.text for symbol in word.symbols])
                confidence = word.confidence
                bounding_box = word.bounding_box
                # vertices: [top_left, top_right, bottom_right, bottom_left]
```

3. SEGMENTACI√ìN INTELIGENTE POR COORDENADAS
Filtrar solo texto que est√© en la columna de c√©dulas usando bounding boxes.

Implementar:
- Calcular centro X de cada palabra
- Filtrar solo palabras donde: 0.40 * image_width < x_center < 0.60 * image_width
- Esto elimina ruido de otras columnas (nombres, firmas)

4. LANGUAGE HINTS
Configurar contexto de idioma para mejorar precisi√≥n.

Implementar:
```python
image_context = vision.ImageContext(
    language_hints=['es']  # Espa√±ol
)

response = client.document_text_detection(
    image=image,
    image_context=image_context
)
```

5. BATCH PROCESSING
En lugar de 15 llamadas individuales, hacer 1 llamada batch.

Implementar:
- Dividir imagen en 15 regiones (renglones)
- Crear lista de requests
- Usar batch_annotate_images() con hasta 16 im√°genes
- M√°s eficiente, mismo costo

6. PRE-AN√ÅLISIS DE CALIDAD CON IMAGE_PROPERTIES
Detectar im√°genes de mala calidad ANTES de enviar a OCR.

Implementar:
- Llamar image_properties() primero
- Analizar: dominant_colors, crop_hints
- Rechazar im√°genes con problemas graves
- Evita gastar requests en im√°genes in√∫tiles

7. POST-PROCESAMIENTO CON CORRECCI√ìN DE ERRORES COMUNES
Aplicar matriz de confusi√≥n de errores t√≠picos en manuscrito.

Implementar matriz de correcciones:
```python
COMMON_ERRORS = {
    # Car√°cter incorrecto -> Car√°cter correcto
    'l': '1', 'I': '1', '|': '1',  # Confusi√≥n con 1
    'O': '0', 'o': '0',             # Confusi√≥n con 0
    'S': '5', 's': '5',             # Confusi√≥n con 5
    'B': '8',                        # Confusi√≥n con 8
}

def corregir_cedula(text):
    # Si contiene letras, aplicar correcciones
    if not text.isdigit():
        for wrong, correct in COMMON_ERRORS.items():
            text = text.replace(wrong, correct)
    return text
```

8. VALIDACI√ìN CONTEXTUAL DE C√âDULAS
Validar que el resultado tenga sentido como c√©dula colombiana.

Implementar reglas:
- Longitud: 6-10 d√≠gitos
- No puede empezar con 0
- Solo d√≠gitos num√©ricos
- (Opcional) Validar d√≠gito verificador si aplica

9. FILTRADO POR "APARIENCIA" DE C√âDULA
Antes de validaci√≥n final, filtrar palabras que podr√≠an ser c√©dulas.

Implementar:


config.yaml:
```yaml
google_vision:
  enabled: true
  authentication: "application_default"
  
  features:
    use_document_text_detection: true  # CR√çTICO
    use_language_hints: true
    language: "es"
  
  extraction:
    min_confidence: 0.85
    use_bounding_boxes: true
    cedula_column_range: [0.40, 0.60]  # 40%-60% del ancho
  
  post_processing:
    enable_error_correction: true
    enable_contextual_validation: true
    
  quality_check:
    enabled: true
    reject_low_quality: true
  
  batch_processing:
    enabled: true
    max_batch_size: 16
  
  logging:
    log_confidence_scores: true
    log_corrections: true
    save_low_confidence_samples: true
    output_dir: "logs/vision_extractions"
```

TESTING Y MEDICI√ìN:

Crear tests para medir precisi√≥n real:
```python
def test_precision_on_sample(sample_size=500):
    """
    Procesa muestra de 500 hojas y mide precisi√≥n
    """
    results = {
        "total": 0,
        "correct": 0,
        "incorrect": 0,
        "low_confidence": 0,
        "avg_confidence": 0
    }
    
    # Procesar muestra
    # Comparar con ground truth
    # Calcular m√©tricas
    
    precision = results["correct"] / results["total"]
    print(f"Precisi√≥n: {precision * 100:.2f}%")
    
    return results
```

DOCUMENTACI√ìN:

Crear: docs/VISION_API_OPTIMIZATION.md

Debe incluir:
- Explicaci√≥n de cada optimizaci√≥n implementada
- Por qu√© cada una mejora la precisi√≥n
- Configuraciones utilizadas
- Resultados de pruebas (antes vs despu√©s)
- An√°lisis de casos donde falla
- Recomendaci√≥n final: ¬øes suficiente o necesitamos Document AI Custom?

M√âTRICAS DE √âXITO:

Al final de la implementaci√≥n, debes tener:

- Precisi√≥n >= 90%: ‚úÖ Suficiente, no necesitas Document AI Custom
- Precisi√≥n 85-90%: ü§î Decisi√≥n de negocio (costo vs beneficio)
- Precisi√≥n < 85%: ‚ùå Considera Document AI Custom

ENTREGABLES:

1. OptimizedVisionAdapter implementado con TODAS las optimizaciones
2. Sistema de testing para medir precisi√≥n en muestra
3. Dashboard de estad√≠sticas (confianza, errores comunes, etc.)
4. Documentaci√≥n completa
5. Reporte final con recomendaci√≥n: ¬øinvertir en Document AI Custom o no?

PRIORIDADES:

1. (CR√çTICO) Migrar a DOCUMENT_TEXT_DETECTION
2. (CR√çTICO) Implementar filtrado por bounding boxes
3. (CR√çTICO) Post-procesamiento con correcci√≥n de errores
4. (ALTO) Sistema de medici√≥n de precisi√≥n
5. (MEDIO) Batch processing
6. (MEDIO) Pre-an√°lisis de calidad
7. (BAJO) Optimizaciones adicionales

Por favor, implementa todas estas optimizaciones y genera un reporte final con la precisi√≥n alcanzada y recomendaci√≥n sobre si es necesario invertir en Document AI Custom.