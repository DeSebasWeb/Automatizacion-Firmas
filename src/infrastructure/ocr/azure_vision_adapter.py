"""Implementaci√≥n de OCR usando Azure Computer Vision Read API v4.0 - Para comparaci√≥n con Google Vision (REFACTORIZADA)."""
import os
from PIL import Image
from typing import List, Dict

try:
    from azure.ai.vision.imageanalysis import ImageAnalysisClient
    from azure.ai.vision.imageanalysis.models import VisualFeatures
    from azure.core.credentials import AzureKeyCredential
    AZURE_VISION_AVAILABLE = True
except ImportError:
    AZURE_VISION_AVAILABLE = False
    print("ADVERTENCIA: Azure Computer Vision no est√° instalado. Instalar con: pip install azure-ai-vision-imageanalysis")

from ...domain.entities import CedulaRecord, RowData
from ...domain.ports import ConfigPort
from .base_ocr_adapter import BaseOCRAdapter
from .image_converter import ImageConverter
from .vision import AzureWordExtractor, ConfidenceMapper


class AzureVisionAdapter(BaseOCRAdapter):
    """
    Implementaci√≥n de OCR usando Azure Computer Vision Read API v4.0.

    **REFACTORIZADA** - Ahora hereda de BaseOCRAdapter eliminando ~350 LOC de duplicaci√≥n.

    Azure Computer Vision es:
    - Especializado en lectura de texto (Read API)
    - Alta precisi√≥n con n√∫meros manuscritos
    - 5,000 transacciones gratis al mes (free tier)
    - Despu√©s: $1 USD por cada 1,000 transacciones

    Para 15 c√©dulas por imagen:
    - 5,000 im√°genes gratis = 75,000 c√©dulas gratis/mes

    Attributes:
        config: Servicio de configuraci√≥n
        client: Cliente de Azure Computer Vision
        preprocessor: Pipeline de preprocesamiento de im√°genes (heredado)
        last_raw_response: √öltima respuesta raw de la API (heredado)
        endpoint: URL del endpoint de Azure
        max_retries: N√∫mero m√°ximo de reintentos
        timeout: Timeout en segundos
    """

    def __init__(self, config: ConfigPort):
        """
        Inicializa el servicio de OCR con Azure Computer Vision.

        Args:
            config: Servicio de configuraci√≥n

        Raises:
            ImportError: Si Azure SDK no est√° instalado
            ValueError: Si faltan credenciales en configuraci√≥n
        """
        if not AZURE_VISION_AVAILABLE:
            raise ImportError(
                "Azure Computer Vision no est√° instalado. "
                "Instalar con: pip install azure-ai-vision-imageanalysis"
            )

        # Inicializar clase base (preprocessor, config, last_raw_response)
        super().__init__(config)

        self.client = None
        self.endpoint = None
        self.max_retries = self.config.get('ocr.azure_vision.max_retries', 3)
        self.timeout = self.config.get('ocr.azure_vision.timeout', 30)

        self._initialize_ocr()

    def _initialize_ocr(self) -> None:
        """
        Inicializa Azure Computer Vision API.

        Busca credenciales en este orden:
        1. Variables de entorno (AZURE_VISION_ENDPOINT, AZURE_VISION_KEY)
        2. Configuraci√≥n en settings.yaml

        Raises:
            ValueError: Si no se encuentran las credenciales
        """
        print("DEBUG Azure Vision: Inicializando cliente...")

        # 1. Intentar desde variables de entorno
        endpoint = os.getenv('AZURE_VISION_ENDPOINT')
        subscription_key = os.getenv('AZURE_VISION_KEY')

        # 2. Si no est√°n en env, intentar desde config
        if not endpoint:
            endpoint = self.config.get('ocr.azure_vision.endpoint')
            # Expandir variables de entorno si est√°n en formato ${VAR}
            if endpoint and endpoint.startswith('${') and endpoint.endswith('}'):
                var_name = endpoint[2:-1]
                endpoint = os.getenv(var_name)

        if not subscription_key:
            subscription_key = self.config.get('ocr.azure_vision.subscription_key')
            # Expandir variables de entorno si est√°n en formato ${VAR}
            if subscription_key and subscription_key.startswith('${') and subscription_key.endswith('}'):
                var_name = subscription_key[2:-1]
                subscription_key = os.getenv(var_name)

        # Validar que tenemos las credenciales
        if not endpoint or not subscription_key:
            error_msg = (
                "ERROR Azure Vision: Faltan credenciales.\n\n"
                "üí° Configura las variables de entorno:\n"
                "   AZURE_VISION_ENDPOINT=https://tu-recurso.cognitiveservices.azure.com/\n"
                "   AZURE_VISION_KEY=tu_subscription_key\n\n"
                "O agrega en config/settings.yaml:\n"
                "   ocr:\n"
                "     azure_vision:\n"
                "       endpoint: https://tu-recurso.cognitiveservices.azure.com/\n"
                "       subscription_key: tu_key\n"
            )
            print(error_msg)
            raise ValueError("Credenciales de Azure Vision no configuradas")

        try:
            # Crear cliente con credenciales
            self.client = ImageAnalysisClient(
                endpoint=endpoint,
                credential=AzureKeyCredential(subscription_key)
            )
            self.endpoint = endpoint

            print("‚úì Azure Computer Vision inicializado correctamente")
            print(f"‚úì Endpoint: {endpoint}")
            print("‚úì Read API v4.0 - Optimizado para texto manuscrito")

        except Exception as e:
            print(f"ERROR Azure Vision: No se pudo inicializar: {e}")
            print("\nüí° Soluciones:")
            print("   1. Verifica que el endpoint sea correcto")
            print("   2. Verifica que la subscription key sea v√°lida")
            print("   3. Aseg√∫rate de tener Computer Vision API habilitado en Azure")
            raise

    def _call_ocr_api(self, image_bytes: bytes) -> any:
        """
        Realiza la llamada a Azure Read API.

        Args:
            image_bytes: Imagen en bytes (PNG format)

        Returns:
            Respuesta de analyze() con feature READ

        Raises:
            Exception: Si hay error en la llamada API
        """
        # Llamar a Azure Read API v4.0
        result = self.client.analyze(
            image_data=image_bytes,
            visual_features=[VisualFeatures.READ]
        )

        return result

    def extract_cedulas(self, image: Image.Image) -> List[CedulaRecord]:
        """
        Extrae n√∫meros de c√©dula de una imagen usando Azure Read API.

        Estrategia:
        1. Preprocesar imagen (mismo pipeline que Google Vision)
        2. Enviar a Azure Read API
        3. Extraer solo n√∫meros de 6-10 d√≠gitos (c√©dulas colombianas)
        4. Filtrar y validar longitud
        5. Retornar como CedulaRecord con Value Objects

        Args:
            image: Imagen PIL a procesar

        Returns:
            Lista de CedulaRecord extra√≠dos
        """
        if self.client is None:
            print("ERROR: Azure Computer Vision no est√° inicializado")
            return []

        print("DEBUG Azure Vision: Iniciando extracci√≥n de c√©dulas...")
        print("DEBUG Azure Vision: Enviando imagen a Read API v4.0")

        try:
            # Preprocesar imagen usando m√©todo heredado
            processed_image = self.preprocess_image(image)

            # Convertir imagen PIL a bytes usando ImageConverter
            img_bytes = ImageConverter.pil_to_bytes(processed_image, format='PNG')

            # Llamar a Azure Read API
            print("DEBUG Azure Vision: Llamando a analyze() con feature READ...")
            result = self._call_ocr_api(img_bytes)

            # Guardar respuesta completa para an√°lisis de confianza por d√≠gito
            self.last_raw_response = result

            print("‚úì Azure Vision: Respuesta recibida")

            # Procesar resultados
            records = []

            if result.read and result.read.blocks:
                print(f"DEBUG Azure Vision: {len(result.read.blocks)} bloques detectados")

                for block in result.read.blocks:
                    for line in block.lines:
                        text = line.text
                        confidence = line.confidence if hasattr(line, 'confidence') else 0.95

                        print(f"DEBUG Azure Vision: L√≠nea detectada: '{text}' (confidence: {confidence:.2f})")

                        # Extraer n√∫meros del texto usando m√©todo heredado
                        numbers = self._extract_numbers_from_text(text)

                        for num in numbers:
                            # Validar longitud de c√©dula colombiana (3-11 d√≠gitos)
                            if 3 <= len(num) <= 11:
                                # Usar factory method para crear con Value Objects
                                record = CedulaRecord.from_primitives(
                                    cedula=num,
                                    confidence=confidence * 100  # Convertir a porcentaje
                                )
                                records.append(record)
                                print(f"‚úì C√©dula extra√≠da: '{num}' ({len(num)} d√≠gitos)")
                            elif len(num) < 3:
                                print(f"‚úó Descartada (muy corta): '{num}' ({len(num)} d√≠gitos)")
                            else:
                                print(f"‚úó Descartada (muy larga): '{num}' ({len(num)} d√≠gitos)")

            # Eliminar duplicados usando m√©todo heredado
            unique_records = self._remove_duplicates(records)

            print(f"DEBUG Azure Vision: Total c√©dulas √∫nicas: {len(unique_records)}")

            return unique_records

        except Exception as e:
            print(f"ERROR Azure Vision: {e}")
            import traceback
            traceback.print_exc()
            return []

    def extract_full_form_data(
        self,
        image: Image.Image,
        expected_rows: int = 15
    ) -> List[RowData]:
        """
        Extrae datos completos del formulario (nombres + c√©dulas) por rengl√≥n.

        ESTRATEGIA OPTIMIZADA (UNA SOLA LLAMADA API):
        1. Enviar imagen COMPLETA a Azure Read API (1 llamada)
        2. Azure detecta TODO el texto con coordenadas
        3. Organizar texto en renglones basado en coordenada Y
        4. Separar nombres (izquierda) y c√©dulas (derecha) por coordenada X

        Args:
            image: Imagen PIL del formulario completo
            expected_rows: N√∫mero esperado de renglones (default: 15)

        Returns:
            Lista de RowData, uno por rengl√≥n
        """
        if self.client is None:
            print("ERROR: Azure Computer Vision no est√° inicializado")
            return []

        print(f"\nDEBUG Azure Vision: Extrayendo formulario completo ({expected_rows} renglones)")
        print("DEBUG Azure Vision: Enviando imagen COMPLETA a API (1 sola llamada)")

        try:
            # Preprocesar imagen
            processed_image = self.preprocess_image(image)

            # Convertir a bytes
            img_bytes = ImageConverter.pil_to_bytes(processed_image, format='PNG')

            # Llamar a Azure Read API
            print("DEBUG Azure Vision: Llamando a analyze() con feature READ...")
            result = self._call_ocr_api(img_bytes)

            print("‚úì Azure Vision: Respuesta recibida (1 llamada API)")

            # Extraer bloques con coordenadas
            all_blocks = self._extract_text_blocks_with_coords(result)

            # Asignar bloques a renglones por coordenada Y (m√©todo heredado)
            rows_blocks = self._assign_blocks_to_rows(
                all_blocks,
                processed_image.height,
                expected_rows
            )

            # Procesar cada rengl√≥n
            all_rows_data = []

            for row_idx in range(expected_rows):
                blocks_in_row = rows_blocks.get(row_idx, [])

                if not blocks_in_row:
                    # Rengl√≥n vac√≠o
                    row_data = self._create_empty_row(row_idx)
                else:
                    # Procesar bloques usando m√©todo heredado (50% boundary para Azure)
                    row_data = self._process_row_blocks(
                        blocks_in_row,
                        row_idx,
                        processed_image.width,
                        column_boundary_ratio=0.5  # 50% para Azure Vision
                    )

                all_rows_data.append(row_data)

            print(f"‚úì Azure Vision: Total renglones procesados: {len(all_rows_data)}")
            print(f"‚úì Azure Vision: Total llamadas API: 1 (√≥ptimo)")

            return all_rows_data

        except Exception as e:
            print(f"ERROR Azure Vision: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _extract_text_blocks_with_coords(
        self,
        result
    ) -> List[Dict]:
        """
        Extrae bloques de texto con coordenadas desde resultado de Azure.

        Args:
            result: Resultado de Azure analyze()

        Returns:
            Lista de dicts con: text, x, y, confidence
        """
        blocks = []

        if not result.read or not result.read.blocks:
            return blocks

        for block in result.read.blocks:
            for line in block.lines:
                # Azure devuelve bounding box como lista de puntos
                if hasattr(line, 'bounding_polygon') and line.bounding_polygon:
                    # Tomar el primer punto como referencia (esquina superior izquierda)
                    x = line.bounding_polygon[0].x
                    y = line.bounding_polygon[0].y
                else:
                    # Fallback si no hay coordenadas
                    x = 0
                    y = 0

                confidence = line.confidence if hasattr(line, 'confidence') else 0.95

                blocks.append({
                    'text': line.text,
                    'x': x,
                    'y': y,
                    'confidence': confidence
                })

        return blocks

    def get_character_confidences(self, text: str) -> Dict[str, any]:
        """
        Extrae la confianza individual de cada caracter en el texto detectado.

        REFACTORIZADO - Ahora usa AzureWordExtractor y ConfidenceMapper.

        Args:
            text: El texto (cedula) para el cual queremos las confianzas

        Returns:
            Dict con:
            - 'confidences': List[float] con confianza de cada caracter (0.0-1.0)
            - 'positions': List[int] con posicion de cada caracter
            - 'average': float con confianza promedio
            - 'source': str identificando el origen

        Raises:
            ValueError: Si no hay respuesta disponible (ejecuta extract_cedulas() primero)
        """
        if not self.last_raw_response:
            raise ValueError("No hay respuesta disponible. Ejecuta extract_cedulas() primero.")

        if not self.last_raw_response.read or not self.last_raw_response.read.blocks:
            print("ADVERTENCIA: No hay datos de lectura en respuesta de Azure Vision")
            # Fallback: confianza uniforme
            return {
                'confidences': [0.85] * len(text),
                'positions': list(range(len(text))),
                'average': 0.85,
                'source': 'azure_vision'
            }

        # PASO 1: Extraer palabras usando AzureWordExtractor
        try:
            words = AzureWordExtractor.extract_all_words(self.last_raw_response)
        except ValueError as e:
            print(f"ADVERTENCIA: Error extrayendo palabras: {e}")
            return {
                'confidences': [0.85] * len(text),
                'positions': list(range(len(text))),
                'average': 0.85,
                'source': 'azure_vision'
            }

        # PASO 2: Mapear texto a confianzas usando ConfidenceMapper
        result = ConfidenceMapper.map_from_words(text, words)

        # PASO 3: Agregar advertencia si no se encontro
        if not result['found']:
            print(f"ADVERTENCIA: Texto '{text}' no encontrado en respuesta de Azure Vision")

        # PASO 4: Agregar source y retornar
        result['source'] = 'azure_vision'
        return result
