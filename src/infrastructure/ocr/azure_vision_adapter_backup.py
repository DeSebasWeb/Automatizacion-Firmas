"""Implementaci√≥n de OCR usando Azure Computer Vision Read API v4.0 - Para comparaci√≥n con Google Vision."""
import re
import os
import time
from PIL import Image
from typing import List, Dict
import io

try:
    from azure.ai.vision.imageanalysis import ImageAnalysisClient
    from azure.ai.vision.imageanalysis.models import VisualFeatures
    from azure.core.credentials import AzureKeyCredential
    AZURE_VISION_AVAILABLE = True
except ImportError:
    AZURE_VISION_AVAILABLE = False
    print("ADVERTENCIA: Azure Computer Vision no est√° instalado. Instalar con: pip install azure-ai-vision-imageanalysis")

from ...domain.entities import CedulaRecord, RowData
from ...domain.ports import OCRPort, ConfigPort
from ..image import ImagePreprocessor


class AzureVisionAdapter(OCRPort):
    """
    Implementaci√≥n de OCR usando Azure Computer Vision Read API v4.0.

    Azure Computer Vision es:
    - Especializado en lectura de texto (Read API)
    - Alta precisi√≥n con n√∫meros manuscritos
    - 5,000 transacciones gratis al mes (free tier)
    - Despu√©s: $1 USD por cada 1,000 transacciones

    Para 15 c√©dulas por imagen:
    - 5,000 im√°genes gratis = 75,000 c√©dulas gratis/mes

    PREPROCESAMIENTO:
    - Reutiliza el mismo pipeline que Google Vision para comparaci√≥n justa
    - Upscaling 3x, denoising, CLAHE, sharpening, etc.

    Attributes:
        config: Servicio de configuraci√≥n
        client: Cliente de Azure Computer Vision
        preprocessor: Pipeline de preprocesamiento de im√°genes
        endpoint: URL del endpoint de Azure
        max_retries: N√∫mero m√°ximo de reintentos
        timeout: Timeout en segundos
    """

    def __init__(self, config: ConfigPort):
        """
        Inicializa el servicio de OCR con Azure Computer Vision.

        Args:
            config: Servicio de configuraci√≥n

        Raises:
            ImportError: Si Azure SDK no est√° instalado
            ValueError: Si faltan credenciales en configuraci√≥n
        """
        if not AZURE_VISION_AVAILABLE:
            raise ImportError(
                "Azure Computer Vision no est√° instalado. "
                "Instalar con: pip install azure-ai-vision-imageanalysis"
            )

        self.config = config
        self.client = None
        self.last_raw_response = None  # Para guardar respuesta completa y extraer confianza por d√≠gito

        # Inicializar preprocesador con la MISMA configuraci√≥n que Google Vision
        preprocessing_config = self.config.get('image_preprocessing', {})
        self.preprocessor = ImagePreprocessor(preprocessing_config)

        # Configuraci√≥n de Azure
        self.endpoint = None
        self.max_retries = self.config.get('ocr.azure_vision.max_retries', 3)
        self.timeout = self.config.get('ocr.azure_vision.timeout', 30)

        self._initialize_ocr()

    def _initialize_ocr(self) -> None:
        """
        Inicializa Azure Computer Vision API.

        Busca credenciales en este orden:
        1. Variables de entorno (AZURE_VISION_ENDPOINT, AZURE_VISION_KEY)
        2. Configuraci√≥n en settings.yaml

        Raises:
            ValueError: Si no se encuentran las credenciales
        """
        print("DEBUG Azure Vision: Inicializando cliente...")

        # 1. Intentar desde variables de entorno
        endpoint = os.getenv('AZURE_VISION_ENDPOINT')
        subscription_key = os.getenv('AZURE_VISION_KEY')

        # 2. Si no est√°n en env, intentar desde config
        if not endpoint:
            endpoint = self.config.get('ocr.azure_vision.endpoint')
            # Expandir variables de entorno si est√°n en formato ${VAR}
            if endpoint and endpoint.startswith('${') and endpoint.endswith('}'):
                var_name = endpoint[2:-1]  # Extraer nombre de variable
                endpoint = os.getenv(var_name)

        if not subscription_key:
            subscription_key = self.config.get('ocr.azure_vision.subscription_key')
            # Expandir variables de entorno si est√°n en formato ${VAR}
            if subscription_key and subscription_key.startswith('${') and subscription_key.endswith('}'):
                var_name = subscription_key[2:-1]  # Extraer nombre de variable
                subscription_key = os.getenv(var_name)

        # Validar que tenemos las credenciales
        if not endpoint or not subscription_key:
            error_msg = (
                "ERROR Azure Vision: Faltan credenciales.\n\n"
                "üí° Configura las variables de entorno:\n"
                "   AZURE_VISION_ENDPOINT=https://tu-recurso.cognitiveservices.azure.com/\n"
                "   AZURE_VISION_KEY=tu_subscription_key\n\n"
                "O agrega en config/settings.yaml:\n"
                "   ocr:\n"
                "     azure_vision:\n"
                "       endpoint: https://tu-recurso.cognitiveservices.azure.com/\n"
                "       subscription_key: tu_key\n"
            )
            print(error_msg)
            raise ValueError("Credenciales de Azure Vision no configuradas")

        try:
            # Crear cliente con credenciales
            self.client = ImageAnalysisClient(
                endpoint=endpoint,
                credential=AzureKeyCredential(subscription_key)
            )
            self.endpoint = endpoint

            print("‚úì Azure Computer Vision inicializado correctamente")
            print(f"‚úì Endpoint: {endpoint}")
            print("‚úì Read API v4.0 - Optimizado para texto manuscrito")

        except Exception as e:
            print(f"ERROR Azure Vision: No se pudo inicializar: {e}")
            print("\nüí° Soluciones:")
            print("   1. Verifica que el endpoint sea correcto")
            print("   2. Verifica que la subscription key sea v√°lida")
            print("   3. Aseg√∫rate de tener Computer Vision API habilitado en Azure")
            raise

    def preprocess_image(self, image: Image.Image) -> Image.Image:
        """
        Preprocesa una imagen para Azure Vision usando el MISMO pipeline que Google Vision.

        Esto es CR√çTICO para comparaci√≥n justa entre ambos proveedores.

        Aplica preprocesamiento intensivo:
        1. Upscaling (3x) - distingue 1 vs 7
        2. Conversi√≥n a escala de grises
        3. Reducci√≥n de ruido (fastNlMeansDenoising)
        4. Aumento de contraste adaptativo (CLAHE)
        5. Sharpening para nitidez
        6. Binarizaci√≥n m√©todo Otsu
        7. Operaciones morfol√≥gicas (Close + Open)

        Args:
            image: Imagen PIL a preprocesar

        Returns:
            Imagen preprocesada y optimizada
        """
        print(f"\nDEBUG Azure Vision: Imagen original {image.width}x{image.height}")

        # Verificar si el preprocesamiento est√° habilitado
        if not self.config.get('image_preprocessing.enabled', True):
            print("DEBUG Azure Vision: Preprocesamiento deshabilitado, usando imagen original")
            if image.mode != 'RGB':
                image = image.convert('RGB')
            return image

        # Aplicar el MISMO pipeline que Google Vision
        processed_image = self.preprocessor.preprocess(image)

        # Azure Vision acepta RGB, PNG, JPEG
        if processed_image.mode != 'RGB':
            processed_image = processed_image.convert('RGB')

        print(f"DEBUG Azure Vision: Imagen procesada {processed_image.width}x{processed_image.height}")

        return processed_image

    def extract_cedulas(self, image: Image.Image) -> List[CedulaRecord]:
        """
        Extrae n√∫meros de c√©dula de una imagen usando Azure Read API.

        Estrategia:
        1. Preprocesar imagen (mismo pipeline que Google Vision)
        2. Enviar a Azure Read API
        3. Extraer solo n√∫meros de 6-10 d√≠gitos (c√©dulas colombianas)
        4. Filtrar y validar longitud
        5. Retornar como CedulaRecord con Value Objects

        Args:
            image: Imagen PIL a procesar

        Returns:
            Lista de CedulaRecord extra√≠dos
        """
        if self.client is None:
            print("ERROR: Azure Computer Vision no est√° inicializado")
            return []

        print("DEBUG Azure Vision: Iniciando extracci√≥n de c√©dulas...")
        print("DEBUG Azure Vision: Enviando imagen a Read API v4.0")

        try:
            # Preprocesar imagen
            processed_image = self.preprocess_image(image)

            # Convertir imagen PIL a bytes
            img_byte_arr = io.BytesIO()
            processed_image.save(img_byte_arr, format='PNG')
            img_byte_arr = img_byte_arr.getvalue()

            # Llamar a Azure Read API v4.0
            print("DEBUG Azure Vision: Llamando a analyze() con feature READ...")
            result = self.client.analyze(
                image_data=img_byte_arr,
                visual_features=[VisualFeatures.READ]
            )

            # Guardar respuesta completa para an√°lisis de confianza por d√≠gito
            self.last_raw_response = result

            print("‚úì Azure Vision: Respuesta recibida")

            # Procesar resultados
            records = []

            if result.read and result.read.blocks:
                print(f"DEBUG Azure Vision: {len(result.read.blocks)} bloques detectados")

                for block in result.read.blocks:
                    for line in block.lines:
                        text = line.text
                        confidence = line.confidence if hasattr(line, 'confidence') else 0.95

                        print(f"DEBUG Azure Vision: L√≠nea detectada: '{text}' (confidence: {confidence:.2f})")

                        # Extraer n√∫meros del texto
                        numbers = self._extract_numbers_from_text(text)

                        for num in numbers:
                            # Validar longitud de c√©dula colombiana (6-10 d√≠gitos)
                            if 3 <= len(num) <= 11:
                                # Usar factory method para crear con Value Objects
                                record = CedulaRecord.from_primitives(
                                    cedula=num,
                                    confidence=confidence * 100  # Convertir a porcentaje
                                )
                                records.append(record)
                                print(f"‚úì C√©dula extra√≠da: '{num}' ({len(num)} d√≠gitos)")
                            elif len(num) < 3:
                                print(f"‚úó Descartada (muy corta): '{num}' ({len(num)} d√≠gitos)")
                            else:
                                print(f"‚úó Descartada (muy larga): '{num}' ({len(num)} d√≠gitos)")

            # Eliminar duplicados
            unique_records = self._remove_duplicates(records)

            print(f"DEBUG Azure Vision: Total c√©dulas √∫nicas: {len(unique_records)}")

            return unique_records

        except Exception as e:
            print(f"ERROR Azure Vision: {e}")
            import traceback
            traceback.print_exc()
            return []

    def extract_full_form_data(
        self,
        image: Image.Image,
        expected_rows: int = 15
    ) -> List[RowData]:
        """
        Extrae datos completos del formulario (nombres + c√©dulas) por rengl√≥n.

        ESTRATEGIA OPTIMIZADA (UNA SOLA LLAMADA API):
        1. Enviar imagen COMPLETA a Azure Read API (1 llamada)
        2. Azure detecta TODO el texto con coordenadas
        3. Organizar texto en renglones basado en coordenada Y
        4. Separar nombres (izquierda) y c√©dulas (derecha) por coordenada X

        Args:
            image: Imagen PIL del formulario completo
            expected_rows: N√∫mero esperado de renglones (default: 15)

        Returns:
            Lista de RowData, uno por rengl√≥n
        """
        if self.client is None:
            print("ERROR: Azure Computer Vision no est√° inicializado")
            return []

        print(f"\nDEBUG Azure Vision: Extrayendo formulario completo ({expected_rows} renglones)")
        print("DEBUG Azure Vision: Enviando imagen COMPLETA a API (1 sola llamada)")

        try:
            # Preprocesar imagen
            processed_image = self.preprocess_image(image)

            # Convertir a bytes
            img_byte_arr = io.BytesIO()
            processed_image.save(img_byte_arr, format='PNG')
            img_byte_arr = img_byte_arr.getvalue()

            # Llamar a Azure Read API
            print("DEBUG Azure Vision: Llamando a analyze() con feature READ...")
            result = self.client.analyze(
                image_data=img_byte_arr,
                visual_features=[VisualFeatures.READ]
            )

            print("‚úì Azure Vision: Respuesta recibida (1 llamada API)")

            # Extraer bloques con coordenadas
            all_blocks = self._extract_text_blocks_with_coords(result, processed_image.height)

            # Asignar bloques a renglones por coordenada Y
            rows_blocks = self._assign_blocks_to_rows(all_blocks, processed_image.height, expected_rows)

            # Procesar cada rengl√≥n
            all_rows_data = []

            for row_idx in range(expected_rows):
                blocks_in_row = rows_blocks.get(row_idx, [])
                row_data = self._process_row_blocks(blocks_in_row, row_idx, processed_image.width)
                all_rows_data.append(row_data)

            print(f"‚úì Azure Vision: Total renglones procesados: {len(all_rows_data)}")
            print(f"‚úì Azure Vision: Total llamadas API: 1 (√≥ptimo)")

            return all_rows_data

        except Exception as e:
            print(f"ERROR Azure Vision: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _extract_text_blocks_with_coords(
        self,
        result,
        image_height: int
    ) -> List[Dict]:
        """
        Extrae bloques de texto con coordenadas desde resultado de Azure.

        Args:
            result: Resultado de Azure analyze()
            image_height: Alto de la imagen para normalizaci√≥n

        Returns:
            Lista de dicts con: text, x, y, confidence
        """
        blocks = []

        if not result.read or not result.read.blocks:
            return blocks

        for block in result.read.blocks:
            for line in block.lines:
                # Azure devuelve bounding box como lista de puntos
                if hasattr(line, 'bounding_polygon') and line.bounding_polygon:
                    # Tomar el primer punto como referencia (esquina superior izquierda)
                    x = line.bounding_polygon[0].x
                    y = line.bounding_polygon[0].y
                else:
                    # Fallback si no hay coordenadas
                    x = 0
                    y = 0

                confidence = line.confidence if hasattr(line, 'confidence') else 0.95

                blocks.append({
                    'text': line.text,
                    'x': x,
                    'y': y,
                    'confidence': confidence
                })

        return blocks

    def _assign_blocks_to_rows(
        self,
        blocks: List[Dict],
        image_height: int,
        num_rows: int
    ) -> Dict[int, List[Dict]]:
        """
        Asigna bloques de texto a renglones basado en coordenada Y.

        Similar a la l√≥gica de GoogleVisionAdapter.

        Args:
            blocks: Lista de bloques con coordenadas
            image_height: Alto total de la imagen
            num_rows: N√∫mero de renglones esperados

        Returns:
            Dict donde key=row_index, value=lista de bloques en ese rengl√≥n
        """
        row_height = image_height / num_rows
        rows_blocks = {}

        for block in blocks:
            # Calcular √≠ndice de rengl√≥n basado en Y
            row_index = int(block['y'] / row_height)

            # Asegurar que est√© en rango v√°lido
            row_index = max(0, min(row_index, num_rows - 1))

            if row_index not in rows_blocks:
                rows_blocks[row_index] = []

            rows_blocks[row_index].append(block)

        return rows_blocks

    def _process_row_blocks(
        self,
        blocks: List[Dict],
        row_index: int,
        image_width: int
    ) -> RowData:
        """
        Procesa bloques de un rengl√≥n para extraer nombres y c√©dula.

        Estrategia:
        - Bloques a la IZQUIERDA (< 50% width) ‚Üí nombres
        - Bloques a la DERECHA (>= 50% width) ‚Üí c√©dula

        Args:
            blocks: Lista de bloques en este rengl√≥n
            row_index: √çndice del rengl√≥n
            image_width: Ancho total de la imagen

        Returns:
            RowData con nombres y c√©dula extra√≠dos
        """
        nombres_parts = []
        cedula_parts = []
        confidence_data = {'nombres': 0.0, 'cedula': 0.0}

        middle_x = image_width / 2

        for block in blocks:
            text = block['text'].strip()
            x = block['x']
            conf = block['confidence']

            if x < middle_x:
                # Est√° a la izquierda ‚Üí nombres
                nombres_parts.append(text)
                confidence_data['nombres'] = max(confidence_data['nombres'], conf)
            else:
                # Est√° a la derecha ‚Üí c√©dula
                cedula_parts.append(text)
                confidence_data['cedula'] = max(confidence_data['cedula'], conf)

        # Unir partes
        nombres = ' '.join(nombres_parts).strip()
        cedula_raw = ' '.join(cedula_parts).strip()

        # Limpiar c√©dula (solo n√∫meros)
        cedula = self._clean_cedula(cedula_raw)

        # Crear texto raw para debugging
        raw_text = f"{nombres} | {cedula_raw}".strip()

        # Detectar si es rengl√≥n vac√≠o
        min_confidence = self.config.get('ocr.azure_vision.confidence_threshold', 0.30)
        is_empty = (
            (not nombres and not cedula) or
            (confidence_data.get('nombres', 0) < min_confidence and confidence_data.get('cedula', 0) < min_confidence) or
            (len(nombres) < 2 and len(cedula) < 6)
        )

        # Usar factory method para crear RowData con Value Objects
        return RowData.from_primitives(
            row_index=row_index,
            nombres_manuscritos=nombres,
            cedula=cedula,
            is_empty=is_empty,
            confidence=confidence_data,
            raw_text=raw_text
        )

    def _extract_numbers_from_text(self, text: str) -> List[str]:
        """
        Extrae n√∫meros del texto reconocido.

        ESTRATEGIA MEJORADA:
        Cuando hay letras entre d√≠gitos (ej: "107 116C1931"), NO separar
        en m√∫ltiples n√∫meros. En su lugar, eliminar TODAS las letras y
        espacios, dejando solo d√≠gitos continuos.

        Esto evita que una c√©dula de 10 d√≠gitos se divida en m√∫ltiples fragmentos.

        Args:
            text: Texto reconocido por Azure (ej: "107 116C1931")

        Returns:
            Lista con UN string num√©rico por l√≠nea (ej: ["1071161931"])
        """
        # Eliminar TODOS los caracteres que no sean d√≠gitos
        # Esto incluye: letras, espacios, puntos, comas, guiones, etc.
        text_clean = re.sub(r'[^\d]', '', text)

        # Si queda alg√∫n n√∫mero, retornarlo como una sola c√©dula
        if text_clean:
            return [text_clean]
        else:
            return []

    def _clean_cedula(self, cedula_text: str) -> str:
        """
        Limpia texto de c√©dula para extraer solo n√∫meros.

        Args:
            cedula_text: Texto crudo de c√©dula

        Returns:
            String con solo d√≠gitos
        """
        # Remover todo lo que no sea d√≠gito
        cedula_clean = re.sub(r'[^\d]', '', cedula_text)
        return cedula_clean

    def _remove_duplicates(self, records: List[CedulaRecord]) -> List[CedulaRecord]:
        """
        Elimina registros duplicados, manteniendo el de mayor confianza.

        Args:
            records: Lista de registros

        Returns:
            Lista sin duplicados
        """
        seen = {}

        for record in records:
            # Usar .value ya que cedula es CedulaNumber (Value Object)
            cedula_key = record.cedula.value
            # Comparar confidence usando .as_percentage()
            if cedula_key not in seen or record.confidence.as_percentage() > seen[cedula_key].confidence.as_percentage():
                seen[cedula_key] = record

        return list(seen.values())

    def get_character_confidences(self, text: str) -> Dict[str, any]:
        """
        Extrae la confianza individual de cada car√°cter en el texto detectado.

        Azure Read API v4.0 retorna confianza a nivel de palabra en:
        - result.read.blocks[].lines[].words[]

        Args:
            text: El texto (c√©dula) para el cual queremos las confianzas

        Returns:
            Dict con:
            - 'confidences': List[float] con confianza de cada car√°cter (0.0-1.0)
            - 'positions': List[int] con posici√≥n de cada car√°cter
            - 'average': float con confianza promedio
            - 'source': str identificando el origen

        Example:
            >>> confidences = adapter.get_character_confidences("1036221525")
            >>> confidences
            {
                'confidences': [0.97, 0.94, 0.98, 0.95, ...],
                'positions': [0, 1, 2, 3, ...],
                'average': 0.962,
                'source': 'azure_vision'
            }

        Raises:
            ValueError: Si no hay respuesta disponible (ejecuta extract_cedulas() primero)
        """
        if not self.last_raw_response:
            raise ValueError("No hay respuesta disponible. Ejecuta extract_cedulas() primero.")

        if not self.last_raw_response.read or not self.last_raw_response.read.blocks:
            print("ADVERTENCIA: No hay datos de lectura en respuesta de Azure Vision")
            # Fallback: confianza uniforme
            return {
                'confidences': [0.85] * len(text),
                'positions': list(range(len(text))),
                'average': 0.85,
                'source': 'azure_vision'
            }

        # Limpiar el texto buscado (eliminar espacios, puntos, etc)
        text_clean = text.replace(' ', '').replace('.', '').replace(',', '').replace('-', '')

        # Extraer todas las palabras con sus confianzas
        all_words = []

        # Iterar sobre la estructura de Azure Vision Read API
        for block in self.last_raw_response.read.blocks:
            for line in block.lines:
                # Azure Read API da words con confianza
                if hasattr(line, 'words') and line.words:
                    for word in line.words:
                        word_text = word.text
                        word_confidence = word.confidence if hasattr(word, 'confidence') else 0.95

                        all_words.append({
                            'text': word_text,
                            'confidence': word_confidence
                        })

        # Construir string de todas las palabras (solo d√≠gitos)
        all_text = ''.join([w['text'] for w in all_words])
        all_text_clean = ''.join([c for c in all_text if c.isdigit()])

        # Intentar encontrar el texto buscado en el texto detectado
        confidences = []
        positions = []

        if text_clean in all_text_clean:
            # Encontrado - extraer confianzas correspondientes
            start_idx = all_text_clean.index(text_clean)

            # Mapear √≠ndices a confianzas de palabras
            digit_counter = 0
            for word in all_words:
                word_text = word['text']
                word_conf = word['confidence']

                # Procesar cada car√°cter de la palabra
                for char in word_text:
                    if char.isdigit():
                        if digit_counter >= start_idx and digit_counter < start_idx + len(text_clean):
                            # Este d√≠gito es parte de la c√©dula buscada
                            confidences.append(word_conf)
                            positions.append(digit_counter - start_idx)
                        digit_counter += 1
        else:
            # No encontrado - usar confianza uniforme basada en promedio general
            print(f"ADVERTENCIA: Texto '{text_clean}' no encontrado en respuesta de Azure Vision")
            print(f"DEBUG: Texto detectado: '{all_text_clean[:100]}...'")

            # Calcular confianza promedio de todas las palabras con d√≠gitos
            numeric_words = [w for w in all_words if any(c.isdigit() for c in w['text'])]
            avg_conf = sum(w['confidence'] for w in numeric_words) / len(numeric_words) if numeric_words else 0.90

            confidences = [avg_conf] * len(text_clean)
            positions = list(range(len(text_clean)))

        # Calcular promedio
        average = sum(confidences) / len(confidences) if confidences else 0.0

        return {
            'confidences': confidences,
            'positions': positions,
            'average': average,
            'source': 'azure_vision'
        }

    def _extract_text_blocks_with_positions(self, result) -> List[Dict]:
        """
        Extrae palabras individuales con coordenadas (NO l√≠neas completas).

        CAMBIO IMPORTANTE: Ahora extrae a nivel de PALABRA en lugar de L√çNEA.
        Esto permite que filter_nombres() agrupe correctamente nombres que est√°n
        separados espacialmente, igual que en Google Vision.

        Args:
            result: Resultado de Azure Read API

        Returns:
            Lista de palabras con {text, x, y, width, height, confidence}
        """
        word_blocks = []

        if not result.read or not result.read.blocks:
            return word_blocks

        for block in result.read.blocks:
            for line in block.lines:
                # Extraer cada palabra individual de la l√≠nea
                if not hasattr(line, 'words') or not line.words:
                    continue

                for word in line.words:
                    # Azure retorna polygon con 8 puntos [x1,y1, x2,y2, x3,y3, x4,y4]
                    if not hasattr(word, 'polygon') or not word.polygon:
                        continue

                    polygon = word.polygon
                    if len(polygon) < 8:
                        continue

                    # Extraer coordenadas x, y
                    x_coords = [polygon[i] for i in range(0, len(polygon), 2)]
                    y_coords = [polygon[i] for i in range(1, len(polygon), 2)]

                    min_x = min(x_coords)
                    max_x = max(x_coords)
                    min_y = min(y_coords)
                    max_y = max(y_coords)

                    # Confianza de la palabra
                    word_confidence = word.confidence if hasattr(word, 'confidence') else 0.95

                    if word.text.strip():
                        word_blocks.append({
                            'text': word.text.strip(),
                            'x': min_x,
                            'y': min_y,
                            'width': max_x - min_x,
                            'height': max_y - min_y,
                            'confidence': word_confidence
                        })

        return word_blocks

    def extract_name_cedula_pairs(self, image: Image.Image) -> List[Dict]:
        """
        Extrae pares nombre-c√©dula usando post-procesamiento + proximidad espacial.

        Flujo:
        1. Extraer TODO el texto con coordenadas
        2. Post-procesamiento: filtrar nombres
        3. Post-procesamiento: filtrar c√©dulas
        4. Emparejar por proximidad espacial

        Returns:
            Lista de pares nombre-c√©dula correctamente emparejados
        """
        from .spatial_pairing import SpatialPairing

        print("\n" + "="*80)
        print("AZURE VISION: Extracci√≥n de pares nombre-c√©dula")
        print("="*80)

        # 1. Preprocesar imagen
        processed_image = self.preprocess_image(image)

        # 2. Extraer TODO el texto con coordenadas
        print("[1/4] Extrayendo texto con coordenadas...")

        # Convertir imagen a bytes
        img_byte_arr = io.BytesIO()
        if processed_image.mode != 'RGB':
            processed_image = processed_image.convert('RGB')
        processed_image.save(img_byte_arr, format='PNG')
        image_data = img_byte_arr.getvalue()

        # Llamar a Azure Read API
        result = self.client.analyze(
            image_data=image_data,
            visual_features=[VisualFeatures.READ]
        )

        self.last_raw_response = result

        # Extraer bloques con posiciones
        all_blocks = self._extract_text_blocks_with_positions(result)
        print(f"  ‚úì Extra√≠dos {len(all_blocks)} bloques de texto")

        # 3. Post-procesamiento: filtrar nombres
        print("[2/4] Post-procesando nombres...")
        nombres = SpatialPairing.filter_nombres(all_blocks)
        print(f"  ‚úì Detectados {len(nombres)} nombres")
        for n in nombres:
            print(f"    - {n['text']} (conf: {n['confidence']:.2%})")

        # 4. Post-procesamiento: filtrar c√©dulas
        print("[3/4] Post-procesando c√©dulas...")
        cedulas = SpatialPairing.filter_cedulas(all_blocks)
        print(f"  ‚úì Detectadas {len(cedulas)} c√©dulas")
        for c in cedulas:
            print(f"    - {c['text']} (conf: {c['confidence']:.2%})")

        # 5. Emparejar por proximidad espacial
        print("[4/4] Emparejando por proximidad espacial...")
        pares = SpatialPairing.pair_by_proximity(nombres, cedulas, verbose=True)
        print(f"  ‚úì Emparejados {len(pares)} pares")

        print("="*80 + "\n")

        return pares
