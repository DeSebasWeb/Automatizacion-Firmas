"""Implementaci√≥n de OCR usando Google Cloud Vision API - √ìptimo para escritura manual."""
import re
import os
from PIL import Image
from typing import List, Dict
import io

try:
    from google.cloud import vision
    GOOGLE_VISION_AVAILABLE = True
except ImportError:
    GOOGLE_VISION_AVAILABLE = False
    print("ADVERTENCIA: Google Cloud Vision no est√° instalado. Instalar con: pip install google-cloud-vision")

from ...domain.entities import CedulaRecord, RowData
from ...domain.ports import OCRPort, ConfigPort
from ..image import ImagePreprocessor


class GoogleVisionAdapter(OCRPort):
    """
    Implementaci√≥n de OCR usando Google Cloud Vision API con preprocesamiento avanzado.

    Google Cloud Vision es:
    - Estado del arte para escritura manual
    - Extremadamente preciso con n√∫meros manuscritos
    - 1,000 detecciones gratis al mes
    - Despu√©s: $1.50 por cada 1,000 detecciones

    Para 15 c√©dulas por imagen:
    - 1,000 im√°genes gratis = 15,000 c√©dulas gratis/mes

    MEJORAS DE PREPROCESAMIENTO:
    - Upscaling 3x para mejor resoluci√≥n (distingue 1 vs 7)
    - Reducci√≥n de ruido con fastNlMeansDenoising
    - Aumento de contraste adaptativo (CLAHE)
    - Sharpening para nitidez
    - Binarizaci√≥n m√©todo Otsu
    - Operaciones morfol√≥gicas para limpieza

    Attributes:
        config: Servicio de configuraci√≥n
        client: Cliente de Google Cloud Vision
        preprocessor: Pipeline de preprocesamiento de im√°genes
    """

    def __init__(self, config: ConfigPort):
        """
        Inicializa el servicio de OCR con Google Cloud Vision.

        Args:
            config: Servicio de configuraci√≥n
        """
        if not GOOGLE_VISION_AVAILABLE:
            raise ImportError("Google Cloud Vision no est√° instalado. Instalar con: pip install google-cloud-vision")

        self.config = config
        self.client = None

        # Inicializar preprocesador con configuraci√≥n
        preprocessing_config = self.config.get('image_preprocessing', {})
        self.preprocessor = ImagePreprocessor(preprocessing_config)

        self._initialize_ocr()

    def _initialize_ocr(self) -> None:
        """Inicializa Google Cloud Vision API."""
        print("DEBUG Google Vision: Inicializando cliente...")

        try:
            # Intentar crear cliente con Application Default Credentials (ADC)
            # ADC busca credenciales en este orden:
            # 1. GOOGLE_APPLICATION_CREDENTIALS (archivo JSON)
            # 2. gcloud auth application-default login (credenciales de usuario)
            # 3. Compute Engine/App Engine/Cloud Run (credenciales de servicio)

            self.client = vision.ImageAnnotatorClient()

            print("‚úì Google Cloud Vision inicializado correctamente")
            print("‚úì Usando Application Default Credentials (ADC)")
            print("‚úì Modelo optimizado para escritura manual")

        except Exception as e:
            print(f"ERROR Google Vision: No se pudo inicializar: {e}")
            print("\nüí° Soluciones:")
            print("   1. Ejecutar: gcloud auth application-default login")
            print("   2. O configurar: GOOGLE_APPLICATION_CREDENTIALS con ruta a JSON")
            print("   3. Aseg√∫rate de habilitar Cloud Vision API en tu proyecto")
            raise

    def preprocess_image(self, image: Image.Image) -> Image.Image:
        """
        Preprocesa una imagen para Google Vision usando pipeline robusto.

        Aplica preprocesamiento intensivo para maximizar precisi√≥n sin aumentar costos:
        1. Upscaling (3x) - CR√çTICO para distinguir 1 vs 7
        2. Conversi√≥n a escala de grises
        3. Reducci√≥n de ruido (fastNlMeansDenoising)
        4. Aumento de contraste adaptativo (CLAHE)
        5. Sharpening para nitidez
        6. Binarizaci√≥n m√©todo Otsu
        7. Operaciones morfol√≥gicas (Close + Open)

        Args:
            image: Imagen PIL a preprocesar

        Returns:
            Imagen preprocesada y optimizada
        """
        print(f"\nDEBUG Google Vision: Imagen original {image.width}x{image.height}")

        # Verificar si el preprocesamiento est√° habilitado
        if not self.config.get('image_preprocessing.enabled', True):
            print("DEBUG Google Vision: Preprocesamiento deshabilitado, usando imagen original")
            if image.mode != 'RGB':
                image = image.convert('RGB')
            return image

        # Aplicar pipeline completo de preprocesamiento
        processed_image = self.preprocessor.preprocess(image)

        # Google Vision requiere RGB, convertir de vuelta si es necesario
        if processed_image.mode != 'RGB':
            processed_image = processed_image.convert('RGB')

        print(f"DEBUG Google Vision: Imagen procesada {processed_image.width}x{processed_image.height}")

        return processed_image

    def extract_cedulas(self, image: Image.Image) -> List[CedulaRecord]:
        """
        Extrae n√∫meros de c√©dula de una imagen usando Google Cloud Vision.

        Estrategia OPTIMIZADA:
        1. Enviar la imagen COMPLETA a Google Vision (1 SOLA llamada API)
        2. Google Vision detecta autom√°ticamente todas las l√≠neas de texto
        3. Extraer solo n√∫meros de 6-10 d√≠gitos que sean c√©dulas v√°lidas

        Esto consume solo 1 petici√≥n API en lugar de 15.

        Args:
            image: Imagen PIL a procesar

        Returns:
            Lista de registros de c√©dulas extra√≠das
        """
        if self.client is None:
            print("ERROR: Google Cloud Vision no est√° inicializado")
            return []

        print("DEBUG Google Vision: Iniciando extracci√≥n...")
        print("DEBUG Google Vision: Enviando imagen completa a API (1 sola llamada)")

        try:
            # Convertir imagen PIL a bytes
            img_byte_arr = io.BytesIO()
            image.save(img_byte_arr, format='PNG')
            img_byte_arr = img_byte_arr.getvalue()

            # Crear objeto Image de Google Vision
            vision_image = vision.Image(content=img_byte_arr)

            # OPTIMIZACI√ìN: Language hints para mejorar precisi√≥n en espa√±ol
            image_context = vision.ImageContext(language_hints=['es'])

            # Llamar a la API - DOCUMENT_TEXT_DETECTION detecta texto l√≠nea por l√≠nea
            # Esta es la √öNICA llamada API que hacemos
            print("DEBUG Google Vision: Llamando a DOCUMENT_TEXT_DETECTION (es)...")
            response = self.client.document_text_detection(
                image=vision_image,
                image_context=image_context
            )

            if response.error.message:
                print(f"ERROR Google Vision API: {response.error.message}")
                return []

            print("‚úì Google Vision: Respuesta recibida (1 llamada API)")

            # Procesar respuesta - Google Vision detecta texto organizado por bloques/l√≠neas
            records = []

            # Opci√≥n 1: Usar full_text_annotation para obtener todo el texto
            if response.full_text_annotation:
                full_text = response.full_text_annotation.text
                print(f"DEBUG Google Vision: Texto completo detectado:\n{full_text}")

                # Procesar l√≠nea por l√≠nea
                lines = full_text.split('\n')
                print(f"DEBUG Google Vision: Detectadas {len(lines)} l√≠neas de texto")

                for idx, line in enumerate(lines):
                    if not line.strip():
                        continue

                    print(f"DEBUG Google Vision: L√≠nea {idx+1}: '{line.strip()}'")

                    # Extraer n√∫meros del texto
                    numbers = self._extract_numbers_from_text(line)

                    for num in numbers:
                        # Validar longitud de c√©dula (3-11 d√≠gitos)
                        if 3 <= len(num) <= 11:
                            # Usar factory method para crear con Value Objects
                            record = CedulaRecord.from_primitives(
                                cedula=num,
                                confidence=95.0  # Google Vision es muy confiable
                            )
                            records.append(record)
                            print(f"‚úì C√©dula extra√≠da: '{num}' ({len(num)} d√≠gitos)")
                        elif len(num) < 3:
                            print(f"‚úó Descartada (muy corta): '{num}' ({len(num)} d√≠gitos)")
                        else:
                            print(f"‚úó Descartada (muy larga): '{num}' ({len(num)} d√≠gitos)")

            print(f"‚úì Google Vision: Total llamadas API: 1 (√≥ptimo)")

            # Eliminar duplicados
            unique_records = self._remove_duplicates(records)

            print(f"DEBUG Google Vision: Total c√©dulas √∫nicas: {len(unique_records)}")

            return unique_records

        except Exception as e:
            print(f"ERROR Google Vision: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _split_image_into_lines(self, image: Image.Image) -> List[Image.Image]:
        """
        Divide la imagen en l√≠neas individuales (una por c√©dula).

        Usa divisi√≥n uniforme: imagen de 490px / 15 l√≠neas = ~32px por l√≠nea

        Args:
            image: Imagen completa

        Returns:
            Lista de sub-im√°genes (una por l√≠nea)
        """
        height = image.height
        width = image.width

        # Dividir en 15 l√≠neas uniformes
        expected_lines = 15
        line_height = height // expected_lines

        print(f"DEBUG Google Vision: Dividiendo imagen en {expected_lines} l√≠neas de {line_height}px cada una")

        regions = []

        for i in range(expected_lines):
            y1 = i * line_height
            y2 = min((i + 1) * line_height, height)

            if y2 - y1 > 10:  # Altura m√≠nima
                region = image.crop((0, y1, width, y2))
                regions.append(region)

        return regions

    def _extract_numbers_from_text(self, text: str) -> List[str]:
        """
        Extrae n√∫meros del texto reconocido.

        Args:
            text: Texto reconocido por Google Vision

        Returns:
            Lista de strings num√©ricos
        """
        # Limpiar texto
        text_clean = text.replace(' ', '').replace('.', '').replace(',', '').replace('-', '').replace('\n', '')

        # Extraer solo n√∫meros
        numbers = re.findall(r'\d+', text_clean)

        return numbers

    def _remove_duplicates(self, records: List[CedulaRecord]) -> List[CedulaRecord]:
        """
        Elimina registros duplicados, manteniendo el de mayor confianza.

        Args:
            records: Lista de registros

        Returns:
            Lista sin duplicados
        """
        seen = {}

        for record in records:
            # Usar .value ya que cedula es ahora CedulaNumber (Value Object)
            cedula_key = record.cedula.value
            # Comparar confidence usando .as_percentage() ya que es ConfidenceScore
            if cedula_key not in seen or record.confidence.as_percentage() > seen[cedula_key].confidence.as_percentage():
                seen[cedula_key] = record

        return list(seen.values())

    def extract_full_form_data(self, image: Image.Image, expected_rows: int = 15) -> List[RowData]:
        """
        Extrae datos completos del formulario manuscrito (nombres + c√©dulas).

        ‚ö° OPTIMIZADO - UNA SOLA LLAMADA API (antes: 15 llamadas)

        ESTRATEGIA OPTIMIZADA:
        1. Enviar imagen COMPLETA a Google Vision (1 llamada API)
        2. Google Vision detecta TODO el texto con coordenadas (bounding boxes)
        3. Organizar texto en renglones basado en coordenada Y
        4. Separar nombres/c√©dulas por columna basado en coordenada X
        5. Detectar renglones vac√≠os

        Esto reduce de 15 llamadas API a 1 SOLA llamada.
        Mejora: 93% reducci√≥n de llamadas API
        Costo: 93% menor
        Velocidad: ~10x m√°s r√°pido

        Args:
            image: Imagen PIL del formulario manuscrito completo
            expected_rows: N√∫mero esperado de renglones (default: 15)

        Returns:
            Lista de RowData (uno por rengl√≥n)
        """
        if self.client is None:
            print("ERROR: Google Cloud Vision no est√° inicializado")
            return []

        print(f"\n{'='*70}")
        print("‚ö° EXTRACCI√ìN OPTIMIZADA - Nombres + C√©dulas (1 SOLA LLAMADA API)")
        print(f"{'='*70}")
        print(f"Imagen: {image.width}x{image.height} px")
        print(f"Renglones esperados: {expected_rows}")

        try:
            # ========== PASO 1: UNA SOLA LLAMADA API ==========
            print("\n[PASO 1] Enviando imagen completa a Google Vision API...")

            # Convertir imagen PIL a bytes
            img_byte_arr = io.BytesIO()
            image.save(img_byte_arr, format='PNG')
            img_byte_arr = img_byte_arr.getvalue()

            # Crear objeto Image de Google Vision
            vision_image = vision.Image(content=img_byte_arr)

            # OPTIMIZACI√ìN: Language hints para mejorar precisi√≥n en espa√±ol
            image_context = vision.ImageContext(language_hints=['es'])

            # ‚ö° √öNICA LLAMADA API - DOCUMENT_TEXT_DETECTION
            response = self.client.document_text_detection(
                image=vision_image,
                image_context=image_context
            )

            if response.error.message:
                print(f"‚úó Error API: {response.error.message}")
                return [self._create_empty_row(i) for i in range(expected_rows)]

            print("‚úì Respuesta recibida (1 llamada API - √ìPTIMO)")

            # Verificar si hay texto detectado
            if not response.full_text_annotation or not response.full_text_annotation.text.strip():
                print("‚úó No se detect√≥ texto en la imagen")
                return [self._create_empty_row(i) for i in range(expected_rows)]

            # ========== PASO 2: ORGANIZAR TEXTO POR RENGLONES ==========
            print(f"\n[PASO 2] Organizando texto en {expected_rows} renglones...")

            # Extraer todos los bloques de texto con coordenadas
            all_blocks = self._extract_text_blocks_with_coords(response)
            print(f"‚úì Detectados {len(all_blocks)} bloques de texto")

            # Dividir bloques en renglones basados en coordenada Y
            rows_blocks = self._assign_blocks_to_rows(
                all_blocks,
                image.height,
                expected_rows
            )

            # ========== PASO 3: PROCESAR CADA RENGL√ìN ==========
            print(f"\n[PASO 3] Procesando {expected_rows} renglones...")

            all_rows_data = []

            for row_idx in range(expected_rows):
                blocks_in_row = rows_blocks.get(row_idx, [])

                if not blocks_in_row:
                    # Rengl√≥n vac√≠o - no hay bloques de texto
                    row_data = self._create_empty_row(row_idx)
                    all_rows_data.append(row_data)
                    print(f"  [{row_idx + 1:2d}] ‚Üí [VAC√çO]")
                else:
                    # Procesar bloques del rengl√≥n
                    row_data = self._process_row_blocks(
                        blocks_in_row,
                        row_idx,
                        image.width
                    )
                    all_rows_data.append(row_data)

                    # Log resultado
                    if row_data.is_empty:
                        print(f"  [{row_idx + 1:2d}] ‚Üí [VAC√çO] (confianza baja)")
                    else:
                        print(f"  [{row_idx + 1:2d}] ‚Üí Nombres: '{row_data.nombres_manuscritos}' | C√©dula: '{row_data.cedula}'")

            # ========== RESUMEN ==========
            print(f"\n{'='*70}")
            print(f"RESUMEN: {len(all_rows_data)} renglones procesados")
            vacios = sum(1 for r in all_rows_data if r.is_empty)
            con_datos = len(all_rows_data) - vacios
            print(f"  - Con datos: {con_datos}")
            print(f"  - Vac√≠os: {vacios}")
            print(f"  - ‚ö° Total llamadas API: 1 (93% reducci√≥n vs antes)")
            print(f"{'='*70}\n")

            return all_rows_data

        except Exception as e:
            print(f"‚úó Error en extracci√≥n: {e}")
            import traceback
            traceback.print_exc()
            return [self._create_empty_row(i) for i in range(expected_rows)]

    def _extract_text_blocks_with_coords(self, response) -> List[Dict]:
        """
        Extrae todos los bloques de texto con sus coordenadas de bounding box.

        Args:
            response: Respuesta de Google Vision API

        Returns:
            Lista de diccionarios con:
                - text: Texto del bloque
                - x: Coordenada X promedio (centro horizontal)
                - y: Coordenada Y promedio (centro vertical)
                - confidence: Confianza del OCR
                - vertices: V√©rtices del bounding box
        """
        blocks = []

        for page in response.full_text_annotation.pages:
            for block in page.blocks:
                # Calcular coordenadas promedio del bloque
                vertices = block.bounding_box.vertices
                if not vertices:
                    continue

                avg_x = sum(v.x for v in vertices) / len(vertices)
                avg_y = sum(v.y for v in vertices) / len(vertices)

                # Extraer texto del bloque
                block_text = ""
                block_confidence = 0.0
                word_count = 0

                for paragraph in block.paragraphs:
                    for word in paragraph.words:
                        word_text = ''.join([symbol.text for symbol in word.symbols])
                        block_text += word_text + " "
                        block_confidence += word.confidence
                        word_count += 1

                block_text = block_text.strip()

                if word_count > 0:
                    block_confidence /= word_count

                if block_text:  # Solo agregar bloques con texto
                    blocks.append({
                        'text': block_text,
                        'x': avg_x,
                        'y': avg_y,
                        'confidence': block_confidence,
                        'vertices': vertices
                    })

        return blocks

    def _assign_blocks_to_rows(
        self,
        blocks: List[Dict],
        image_height: int,
        num_rows: int
    ) -> Dict[int, List[Dict]]:
        """
        Asigna bloques de texto a renglones bas√°ndose en coordenada Y.

        Divide la imagen en renglones uniformes y asigna cada bloque
        al rengl√≥n m√°s cercano seg√∫n su coordenada Y.

        Args:
            blocks: Lista de bloques con coordenadas
            image_height: Altura de la imagen en p√≠xeles
            num_rows: N√∫mero de renglones esperados

        Returns:
            Diccionario {row_index: [bloques]}
        """
        row_height = image_height / num_rows
        rows_blocks = {i: [] for i in range(num_rows)}

        for block in blocks:
            # Determinar a qu√© rengl√≥n pertenece seg√∫n coordenada Y
            row_idx = int(block['y'] / row_height)

            # Asegurar que est√° dentro del rango
            row_idx = max(0, min(row_idx, num_rows - 1))

            rows_blocks[row_idx].append(block)

        return rows_blocks

    def _process_row_blocks(
        self,
        blocks: List[Dict],
        row_index: int,
        image_width: int
    ) -> RowData:
        """
        Procesa bloques de un rengl√≥n separando nombres y c√©dula.

        Separa los bloques en dos columnas bas√°ndose en coordenada X:
        - Columna izquierda (0-60% del ancho): NOMBRES
        - Columna derecha (60-100% del ancho): C√âDULA

        Args:
            blocks: Bloques de texto del rengl√≥n
            row_index: √çndice del rengl√≥n
            image_width: Ancho de la imagen

        Returns:
            RowData con nombres, c√©dula y confianza
        """
        # L√≠mite de columnas (60% del ancho)
        column_boundary = image_width * 0.6

        nombres_parts = []
        cedula_parts = []
        nombres_confidences = []
        cedula_confidences = []

        # Clasificar bloques por columna
        for block in blocks:
            if block['x'] < column_boundary:
                # Columna izquierda - NOMBRES
                nombres_parts.append(block['text'])
                nombres_confidences.append(block['confidence'])
            else:
                # Columna derecha - C√âDULA
                cedula_parts.append(block['text'])
                cedula_confidences.append(block['confidence'])

        # Combinar partes
        nombres = ' '.join(nombres_parts).strip()
        cedula_raw = ' '.join(cedula_parts).strip()

        # OPTIMIZACI√ìN: Corregir errores comunes de OCR antes de limpiar
        cedula = self._corregir_errores_ocr_cedula(cedula_raw)

        # Calcular confianza promedio
        nombres_conf = sum(nombres_confidences) / len(nombres_confidences) if nombres_confidences else 0.0
        cedula_conf = sum(cedula_confidences) / len(cedula_confidences) if cedula_confidences else 0.0

        confidence = {
            'nombres': nombres_conf,
            'cedula': cedula_conf
        }

        # Crear texto raw para debugging
        raw_text = f"{nombres} | {cedula_raw}".strip()

        # Detectar si es rengl√≥n vac√≠o basado en umbral de confianza
        min_confidence = self.config.get('ocr.google_vision.confidence_threshold', 0.30)
        is_empty = (
            (not nombres and not cedula) or
            (confidence.get('nombres', 0) < min_confidence and confidence.get('cedula', 0) < min_confidence) or
            (len(nombres) < 2 and len(cedula) < 6)  # Muy poco texto
        )

        # Usar factory method para crear RowData con Value Objects
        return RowData.from_primitives(
            row_index=row_index,
            nombres_manuscritos=nombres,
            cedula=cedula,
            is_empty=is_empty,
            confidence=confidence,
            raw_text=raw_text
        )

    # ========== M√âTODOS LEGACY (DEPRECADOS) ==========
    # Los siguientes m√©todos ya NO se usan en extract_full_form_data optimizado.
    # Se mantienen por compatibilidad pero no se llaman.

    def _split_image_into_rows(self, image: Image.Image, num_rows: int) -> List[Image.Image]:
        """
        [DEPRECADO] Divide la imagen en renglones horizontales uniformes.

        Este m√©todo ya NO se usa en la versi√≥n optimizada de extract_full_form_data.
        La versi√≥n optimizada procesa la imagen completa en 1 sola llamada API.

        Args:
            image: Imagen completa del formulario
            num_rows: N√∫mero de renglones a crear

        Returns:
            Lista de sub-im√°genes (una por rengl√≥n)
        """
        height = image.height
        width = image.width
        row_height = height // num_rows

        print(f"Divisi√≥n: {height}px / {num_rows} renglones = {row_height}px por rengl√≥n")

        rows = []
        for i in range(num_rows):
            y1 = i * row_height
            y2 = min((i + 1) * row_height, height)

            if y2 - y1 > 5:  # Altura m√≠nima
                row = image.crop((0, y1, width, y2))
                rows.append(row)

        return rows

    def _process_single_row(self, row_image: Image.Image, row_index: int) -> RowData:
        """
        Procesa un rengl√≥n individual extrayendo nombres y c√©dula.

        Estrategia de separaci√≥n por columnas:
        - Columna izquierda (0-50% del ancho): NOMBRES
        - Columna centro (50-100% del ancho): C√âDULA

        Args:
            row_image: Imagen del rengl√≥n a procesar
            row_index: √çndice del rengl√≥n (0-14)

        Returns:
            RowData con nombres, c√©dula, y estado de vac√≠o
        """
        try:
            # Convertir imagen PIL a bytes
            img_byte_arr = io.BytesIO()
            row_image.save(img_byte_arr, format='PNG')
            img_byte_arr = img_byte_arr.getvalue()

            # Crear objeto Image de Google Vision
            vision_image = vision.Image(content=img_byte_arr)

            # OPTIMIZACI√ìN: Language hints para mejorar precisi√≥n en espa√±ol
            image_context = vision.ImageContext(language_hints=['es'])

            # Llamar a la API - DOCUMENT_TEXT_DETECTION
            response = self.client.document_text_detection(
                image=vision_image,
                image_context=image_context
            )

            if response.error.message:
                print(f"  ‚úó Error API: {response.error.message}")
                return self._create_empty_row(row_index)

            # Verificar si hay texto detectado
            if not response.full_text_annotation or not response.full_text_annotation.text.strip():
                print(f"  ‚Üí Sin texto detectado (rengl√≥n vac√≠o)")
                return self._create_empty_row(row_index)

            # Extraer texto completo para debugging
            full_text = response.full_text_annotation.text.strip()
            print(f"  ‚Üí Texto detectado: '{full_text}'")

            # Separar nombres y c√©dula usando coordenadas de boundingBox
            nombres, cedula, confidence = self._separate_nombres_cedula(
                response,
                row_image.width
            )

            # Detectar si es rengl√≥n vac√≠o basado en umbral de confianza
            min_confidence = self.config.get('ocr.google_vision.confidence_threshold', 0.30)
            is_empty = (
                (not nombres and not cedula) or
                (confidence.get('nombres', 0) < min_confidence and confidence.get('cedula', 0) < min_confidence) or
                (len(nombres) < 2 and len(cedula) < 6)  # Muy poco texto
            )

            # Usar factory method para crear RowData con Value Objects
            return RowData.from_primitives(
                row_index=row_index,
                nombres_manuscritos=nombres,
                cedula=cedula,
                is_empty=is_empty,
                confidence=confidence,
                raw_text=full_text
            )

        except Exception as e:
            print(f"  ‚úó Error procesando rengl√≥n: {e}")
            return self._create_empty_row(row_index)

    def _separate_nombres_cedula(
        self,
        response,
        image_width: int
    ) -> tuple[str, str, Dict[str, float]]:
        """
        Separa nombres y c√©dula bas√°ndose en posici√≥n horizontal del texto.

        Columnas del formulario manuscrito:
        - Izquierda (0-60% del ancho): NOMBRES
        - Centro (60-100% del ancho): C√âDULA

        Args:
            response: Respuesta de Google Vision API
            image_width: Ancho de la imagen del rengl√≥n

        Returns:
            (nombres, cedula, confidence_dict)
        """
        # L√≠mite de columnas (60% del ancho)
        column_boundary = image_width * 0.6

        nombres_parts = []
        cedula_parts = []
        nombres_confidences = []
        cedula_confidences = []

        # Iterar sobre los bloques/palabras detectadas
        for page in response.full_text_annotation.pages:
            for block in page.blocks:
                for paragraph in block.paragraphs:
                    # Obtener bounding box del p√°rrafo
                    vertices = paragraph.bounding_box.vertices
                    if not vertices:
                        continue

                    # Calcular posici√≥n X promedio
                    avg_x = sum(v.x for v in vertices) / len(vertices)

                    # Extraer texto del p√°rrafo
                    paragraph_text = ""
                    paragraph_confidence = 0.0
                    word_count = 0

                    for word in paragraph.words:
                        word_text = ''.join([symbol.text for symbol in word.symbols])
                        paragraph_text += word_text + " "
                        paragraph_confidence += word.confidence
                        word_count += 1

                    paragraph_text = paragraph_text.strip()
                    if word_count > 0:
                        paragraph_confidence /= word_count

                    # Clasificar en columna izquierda (nombres) o centro (c√©dula)
                    if avg_x < column_boundary:
                        # Columna izquierda - NOMBRES
                        nombres_parts.append(paragraph_text)
                        nombres_confidences.append(paragraph_confidence)
                    else:
                        # Columna centro - C√âDULA
                        cedula_parts.append(paragraph_text)
                        cedula_confidences.append(paragraph_confidence)

        # Combinar partes
        nombres = ' '.join(nombres_parts).strip()
        cedula_raw = ' '.join(cedula_parts).strip()

        # OPTIMIZACI√ìN: Corregir errores comunes de OCR antes de limpiar
        cedula = self._corregir_errores_ocr_cedula(cedula_raw)

        # Calcular confianza promedio
        nombres_conf = sum(nombres_confidences) / len(nombres_confidences) if nombres_confidences else 0.0
        cedula_conf = sum(cedula_confidences) / len(cedula_confidences) if cedula_confidences else 0.0

        confidence = {
            'nombres': nombres_conf,
            'cedula': cedula_conf
        }

        return nombres, cedula, confidence

    def _corregir_errores_ocr_cedula(self, cedula: str) -> str:
        """
        Corrige errores comunes de OCR en c√©dulas manuscritas.

        OPTIMIZACI√ìN CR√çTICA del prompt.txt:
        Aplica matriz de confusi√≥n para errores t√≠picos en escritura manual.

        Correcciones implementadas:
        - l, I, | ‚Üí 1 (confusi√≥n con n√∫mero 1)
        - O, o ‚Üí 0 (confusi√≥n con cero)
        - S, s ‚Üí 5 (confusi√≥n con 5)
        - B ‚Üí 8 (confusi√≥n con 8)
        - Z, z ‚Üí 2 (confusi√≥n con 2)
        - G ‚Üí 6 (confusi√≥n con 6)

        Args:
            cedula: String de c√©dula potencialmente con errores

        Returns:
            C√©dula corregida con solo d√≠gitos num√©ricos

        Example:
            "lO23456" ‚Üí "1023456"
            "B765432I" ‚Üí "87654321"
        """
        if not cedula:
            return cedula

        # Matriz de correcci√≥n de errores comunes
        COMMON_ERRORS = {
            'l': '1', 'I': '1', '|': '1',  # Confusi√≥n con 1
            'O': '0', 'o': '0',             # Confusi√≥n con 0
            'S': '5', 's': '5',             # Confusi√≥n con 5
            'B': '8',                        # Confusi√≥n con 8
            'Z': '2', 'z': '2',             # Confusi√≥n con 2
            'G': '6',                        # Confusi√≥n con 6
        }

        # Aplicar correcciones car√°cter por car√°cter
        cedula_corregida = ""
        correcciones_aplicadas = []

        for char in cedula:
            if char in COMMON_ERRORS:
                char_corregido = COMMON_ERRORS[char]
                cedula_corregida += char_corregido
                correcciones_aplicadas.append(f"{char}‚Üí{char_corregido}")
            else:
                cedula_corregida += char

        # Log correcciones si se aplicaron
        if correcciones_aplicadas:
            print(f"  üîß Correcciones OCR aplicadas: {', '.join(correcciones_aplicadas)}")
            print(f"     Antes: '{cedula}' ‚Üí Despu√©s: '{cedula_corregida}'")

        # Filtrar solo d√≠gitos num√©ricos
        cedula_final = ''.join(filter(str.isdigit, cedula_corregida))

        return cedula_final

    def _create_empty_row(self, row_index: int) -> RowData:
        """
        Crea un RowData vac√≠o para renglones sin datos.

        Args:
            row_index: √çndice del rengl√≥n

        Returns:
            RowData marcado como vac√≠o
        """
        # Usar factory method para crear RowData con Value Objects
        return RowData.from_primitives(
            row_index=row_index,
            nombres_manuscritos="",
            cedula="",
            is_empty=True,
            confidence={},
            raw_text=None
        )

